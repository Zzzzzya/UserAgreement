#å¯ä»¥è·‘é€šï¼Œä½†éœ€è¦åœ¨ç»ˆç«¯ä¸­è·‘
#ä¸‹æ¬¡è®°å¾—å…ˆã€æ¸…æ´—ã€‘ä¸€ä¸‹æ•°æ®ï¼ŒæŠŠä¸€äº›ç¬¦å·ï¼ˆURLæ ¼å¼ï¼‰ç»Ÿä¸€ï¼Œé¿å…é‡åˆ°å…¨è§’ç¬¦å·å°±å´©æºƒçš„æƒ…å†µâ€¦â€¦

import os
import time
import pandas as pd
from readability_cn import ChineseReadability
from multiprocessing import Pool, cpu_count

# ===== è®¾ç½®è·¯å¾„å’Œæ–‡ä»¶ =====
input_file = "/Users/jitianran/Desktop/jtr/cleaned_data/åè®®æ•°æ®æ±‡æ€»_æ¸…æ´—å.xlsx"
output_file = "/Users/jitianran/Desktop/jtr/cleaned_data/åè®®æ–‡æœ¬_å¯è¯»æ€§åˆ†æç»“æœ_multiprocessing.xlsx"
batch_size = 5  # æ¯æ‰¹å¤„ç† 5 æ¡
num_workers = min(cpu_count(), 4)  # è®¾ç½®æœ€å¤šä½¿ç”¨çš„æ ¸æ•°ï¼ˆä¿å®ˆé€‰æ‹©ï¼‰

# ===== åˆå§‹åŒ–åˆ†æå™¨ï¼Œç”¨äºè·å–è‡ªå®šä¹‰è¯è¡¨ =====
base_readability = ChineseReadability()
custom_words = [
    "çŸ¥ä¹", "æ·˜å®", "å¾®ä¿¡", "æŠ–éŸ³", "äº¬ä¸œ", "æ–°æµªå¾®åš", "ä¼˜é…·", "æ‹¼å¤šå¤š", "å¿«æ‰‹", "ç¾å›¢å¤–å–",
    "å¹³å°", "å…¬å¸", "æˆ‘ä»¬", "è±†ç“£", "ç½‘æ˜“", "eå®¶å¸®", "é“¾å®¶", "å“”å“©å“”å“©", "äººæ°‘ç½‘", "å‡¤å‡°ç½‘",
    "å”¯å“ä¼š", "å–œé©¬æ‹‰é›…", "å¤®è§†ç½‘", "æˆ‘çˆ±æˆ‘å®¶", "æœç‹—", "æºç¨‹", "æ™‹æ±Ÿæ–‡å­¦åŸ", "æ»´æ»´",
    "æ»´ç­”å‡ºè¡Œ", "çˆ±å¥‡è‰º", "ç™¾åº¦", "ç¥å·ä¸“è½¦", "ç½‘æ˜“ä¸¥é€‰", "ç½‘æ˜“æ¸¸æˆ", "è…¾è®¯æ–°é—»", "è…¾è®¯è§†é¢‘",
    "èµ·ç‚¹ä¸­æ–‡ç½‘", "é«˜å¾·", "360", "å°çº¢ä¹¦","å”¯å“ä¼š","è…¾è®¯æ¸¸æˆ","è˜‘è‡å±‹","ç”¨æˆ·", "å¸å·", "æ‚¨", "å¯", "å¯ä»¥", "æœ‰æƒ", "äº«æœ‰", "æ‹¥æœ‰",
    "å¾—ä»¥", "èƒ½å¤Ÿ", "åº”", "åº”å½“", "ä¸å¾—", "æ‰¿æ‹…", "è´Ÿè´£", "å±¥è¡Œ", "å¿…é¡»", "ä¿è¯", "ä¸", "æœª",
    "æ²¡æœ‰", "ä¸ä¼š", "ä¸èƒ½", "å¹¶é", "æ— ", "æ— éœ€"
]
base_readability.add_custom_words(custom_words)

# ===== å­è¿›ç¨‹å·¥ä½œå‡½æ•° =====
def analyze_text(index_text_pair):
    idx, text = index_text_pair
    readability = ChineseReadability()
    readability.add_custom_words(custom_words)

    try:
        if not isinstance(text, str) or len(text.strip()) < 10:
            return idx, None
        sentences = [s.strip() for s in readability.stnsplit.split(text) if s.strip()]
        score = readability.wanglei_readability(sentences)
        print(score)
        result = score

        if result is not None and result < -50:
            print(f"âš ï¸ ç¬¬ {idx + 1} æ¡ä¸ºå¯ç–‘æ–‡æœ¬ï¼Œå‰200å­—ï¼š{text[:200]}")
        return idx, result
    except Exception as e:
        print(f"âŒ ç¬¬ {idx + 1} æ¡å¤„ç†å¤±è´¥ï¼š{e}")
        return idx, None

# ===== ä¸»æ‰§è¡Œå‡½æ•° =====
def main():
    df = pd.read_excel(input_file)

    # ===== å¦‚æœå·²å­˜åœ¨ç»“æœåˆ™æ–­ç‚¹ç»­è·‘ =====
    if os.path.exists(output_file):
        done_df = pd.read_excel(output_file)
        start_idx = len(done_df)
        results = done_df
        print(f"ğŸ” ç»­è·‘æ¨¡å¼ï¼šå·²å®Œæˆ {start_idx} æ¡ï¼Œä»ç¬¬ {start_idx} æ¡å¼€å§‹")
    else:
        start_idx = 0
        results = pd.DataFrame()
        print("ğŸš€ æ–°ä»»åŠ¡å¯åŠ¨ï¼šä»å¤´å¼€å§‹åˆ†æã€‚")

    total = len(df)
    for i in range(start_idx, total, batch_size):
        batch = df.iloc[i:i+batch_size].copy()
        index_text_pairs = [(i + j, row["å†…å®¹_æ¸…æ´—"]) for j, row in batch.iterrows()]

        print(f"ğŸ“¦ æ­£åœ¨å¤„ç†ç¬¬ {i+1} åˆ°ç¬¬ {i+len(batch)} æ¡ï¼Œå…± {len(batch)} æ¡")

        with Pool(processes=num_workers) as pool:
            score_results = pool.map(analyze_text, index_text_pairs)

        scores = [None] * len(batch)
        for idx, score in score_results:
            print("idx:", idx, "i:", i, "score:", score)
            local_j = idx - i
            scores[local_j] = score
            print(f"âœ… ç¬¬ {idx+1} æ¡å®Œæˆï¼Œå¾—åˆ†ï¼š{score}")
            time.sleep(0.05)

        batch["å¯è¯»æ€§åˆ†æ•°"] = scores
        results = pd.concat([results, batch], ignore_index=True)
        results.to_excel(output_file, index=False)
        print(f"ğŸ’¾ å·²ä¿å­˜åˆ°ç¬¬ {i + len(batch)} æ¡\n")

    print("ğŸ‰ å…¨éƒ¨å¤„ç†å®Œæˆï¼")

# ===== å¯åŠ¨ç¨‹åº =====
if __name__ == "__main__":
    main()